
\section{第十五章  語料庫與語言研究的實證方法}

謝舒凱

國立臺灣大學語言學研究所

15.1 背景

15.1.1 相關學門分支

15.1.2 實證方法

15.1.3 語料庫與語言資源

15.2 語料庫工具

15.2.1 整體式網路服務

15.2.2 語料庫程式設計

15.3 語言研究的實證方法

15.3.1 程序

15.3.2 方法論上的考量

15.4 應用

15.5 總結與摘要

15.6 參考文獻

“\textit{Whereof} \textit{one} \textit{cannot} \textit{speak,} \textit{thereof} \textit{one} \textit{must} \textit{be} \textit{silent”}

\textit{{}---} \textbf{\textit{Ludwig} \textit{Wittgenstein}}

\subsection{15.1 背景}

語言是個屬於人類的內在\textbf{複雜系統}[FF08?]參見第一章[FF09?]。我們想要探究語言[FF0C?]可以立基於內在的直覺語感[FF0C?]或是從語言習得的歷程、或語言實際使用與溝通的情境中去觀察與剖析。從語言學的發展歷史來看[FF0C?]我們可以發現近二十年來[FF0C?]實證與量化研究趨勢 (quantitative/empirical turn) (Luodonpää-Manni, Penttilä, and Viimaranta (\hyperlink{bookmarkid28h4qwu}{2017})) 漸漸的受到重視。這個背景可以說是由多個因素所共同造成[FF0C?]包括理論範式的變遷、語料庫的興起與語言科技的迅速發展。

從認知語言學家 \parencite{Langacker1987} 開始[FF0C?]許多學者開始意識到語言結構與意義是由使用中形塑與突現[FF0C?]這個想法可以用「基於使用的語言學」(usage-based linguistics) 來稱呼 (Diessel (\hyperlink{bookmarkid2grqrue}{2017}))。這個觀點下[FF0C?]語言是個流動的範疇與限制的系統[FF0C?]由實際使用中各種高等認知過程交互作用下不斷地重新結構與組織。因此[FF0C?]語言學家對於語言使用的工具與方法論就越來越重視。如何掌握語言使用的實際資料[FF0C?]也促發了理論與語料的密切結合。本章節要介紹的是語言學研究的實證方法[FF0C?]特別是以語料庫為本的取徑。

\subsubsection{15.1.1 相關學門分支}

從語言學史上看[FF0C?]使用數學與統計方法探究語言並不是什麼新的想法。談到實證方法[FF0C?]我們可以先區分幾個相關且相互交疊的領域[FF1A?]

\begin{itemize}
\item \textbf{計量語言學} (quantitative linguistics) 重視的是語言定律 (language law) 的發現。如「齊夫定律」 (zipf law) (Zipf \hyperlink{bookmarkid2lwamvv}{1949}) 發現的是在自然語言的語料庫裡單詞出現的頻率與它在頻率表中的排名成反比[FF1B?]曼則拉—阿圖曼定律 (Menzerath-Altmann law) 則發現了語言表達的內部單位長度與其組成的結構單位長度成反比[FF0C?]例如句子越長[FF0C?]組成它的子句就越短。

\item \textbf{語料庫語言學} (corpus linguistics) 著重在語言樣本的蒐集、標記與分析。在 1960 年代[FF0C?]社會語言學家 William Labov 即開始推動社會語言學的實證研究[FF1B?]與此同時[FF0C?]第一個英語語料庫也誕生。語料庫可以說是語言使用的「樣本」[FF0C?]我們可以藉由「樣本」的分析與觀察[FF0C?]進而預測與理解語言的本質。也因為「樣本」的概念[FF0C?]很自然的與統計方法有密切的連結。語料庫可以說是語言研究實證方法的最大催生力量[FF0C?]也是語言學研究社群在近年來成長最快的一個分支。

\item \textbf{計算語言學} (computational linguistics) 則試圖建立自然語言的計算模型[FF0C?]除了可用來模擬人類的語言行為[FF0C?]也可以結合語言科技應用[FF0C?]讓機器得以學習處理和理解人類的自然語言。

\end{itemize}
\subsubsection{15.1.2 實證方法}

以上提到這些學門之間的相同點在於實證方法的重視。實證方法的優點之一是提供較高程度的客觀性、可比較性與可重製性 (reproducible)。可重製性的定義雖然仍有爭議[FF0C?]不過大體上說的是一種科學精神[FF1A?]在給定相同的樣本數據、假說、實驗設計甚至程式工具[FF0C?]我們應該可以預期得到一致的估計參數或結果。之前的語言學研究中因為理論側重不同[FF0C?]語料取得與使用的技術也不成熟[FF0C?]實證方法顯得比較不被看重[FF0C?]甚至有所排斥。但是放在科學研究的進展來看[FF0C?]可重製的實驗可以推動理論進步[FF0C?]降低研究發現是偶發、隨選或造假的風險[FF0C?]因此在語言研究社區中也慢慢為人接受。那麼實證方法與思維要能實際作用[FF0C?]其中有個重要的關鍵在於「資料」或稱「數據」(data)。和語言產出、使用、分析有關的資料我們可以稱之為語言資料 (linguistic data)[FF0C?]其中最為廣泛使用與分析的是語言自然使用的語料 (corpus data)[FF0C?]和用語言田野工作或相關實驗導出的資料 (elicited data)。隨著當前的語言科技進展倍速[FF0C?]在語料的錄製、辨識、前置處理、標記、並列、校準、分析建模、視覺化等方面[FF0C?]實證方法在語料處理與分析上的應用可以說是已經達到相當的成就。

\subsubsection{15.1.3 語料庫與語言資源}

任何以語言溝通系統為主的數位化資源[FF0C?]我們都可以稱之為「語言資源」(language resource)。其中作為語言使用的代表性樣本的語料庫可以說是最為典型的一種語言資源。語料庫 (corpus) 與語料庫為本 (corpus-based) 的研究[FF0C?]也可以說是當前語言學研究的核心的方法之一。它也是語言實證研究的主要的工具之一。那麼什麼是語料庫呢[FF1F?]語料庫語言學家 \parencite{Gries2019} 認為一個典型的語料庫需符合幾個條件[FF1A?](1). (口語或文本)語料符合機讀格式 (machine-readable)[FF0C?](2). 語料是在自然溝通語境下蒐集得到的[FF0C?](3). 就蒐集對象來說要考量到樣本代表性[FF0C?]在文類、文體變異也要取得平衡。(4). 要能夠被編制成便利語言學分析的樣式。

當前大部分語言相關的研究在不同程度範圍內[FF0C?]都使用到語料庫資源與工具。此外[FF0C?]從時代背景來看[FF0C?]隨著社交媒體與社會網路的發展[FF0C?]非結構性的文本資料所占比例已遠超過結構性的表格性資料[FF0C?]使得文本的語言分析在資訊發展中的角色也顯得愈來愈吃重[FF0C?]連帶的語料庫與分析方法更擴及到語言與教學研究、社會科學、神經心理與認知科學研究上。

近年來光在語料庫語言學的發展進程上[FF0C?]就產生了許多新的趨勢。例如在來源取得方面[FF0C?]傳統手製語料庫的方式[FF0C?]已經轉向半自動建立之巨型語料庫[FF0C?]一直到網路作為語料庫 (web as corpus) 之實現。特別是社會媒體網路可能是一個最為相關且有趣的語料來源。網路時代的線上生活[FF0C?]不僅提供活生生的當代語言使用資料[FF0C?]更重要的是還有彼此相互連結的人際溝通意圖訊息。在以前因礙於語料取得困難[FF0C?]傳統的語料庫概念比較假定文本的封閉靜態[FF0C?]使得語言行為呈現單調[FF0C?]樣本亦常常受限代表性的問題而欠缺說服力。諸如多模態語料 (multimodality)、領域語言 (sublanguage)、個人習語 (idiolect)、領域知識本體 (domain ontology) 等研究與應用[FF0C?]都難以展開至一定規模[FF0C?]而今語料的大量可得性像是開啟了潘朵拉的盒子。這些巨量與多元的語料開始讓我們有機會重新思考一些語言學的幾個基本爭論點[FF1A?]語料是什麼[FF1F?]語料與語言理論的關係是什麼[FF1F?]語言學習者需要的語料是什麼[FF1F?]有哪些[FF1F?]等等。

此外[FF0C?]在語料的多元方面[FF0C?]語言資源除了以語言使用「共面」(syntagmatic) 為主的語料庫之外[FF0C?]尚有以「立面」(paradigmatic) 詞彙資源為主者[FF0C?]像是同義詞辭林 (Thesaurus)、詞彙網路 (WordNet)、框架語意 (FrameNet) 等詞彙與詞典資源。目前在正體字華語社群中[FF0C?]以\href{https://lope.linguistics.ntu.edu.tw/cwn2/}{中文詞彙網路}\href{https://lope.linguistics.ntu.edu.tw/cwn2/}{ (Chinese Wordnet)} (Huang et al.~2010) 和\href{http://ehownet.iis.sinica.edu.tw/}{繁體知網}\href{http://ehownet.iis.sinica.edu.tw/}{(eHowNet)} 為分析與標記最完整的詞彙知識庫。以中文詞彙網路為例[FF0C?]它的設計理念是在完整的詞彙知識系統下[FF0C?]兼顧詞義與詞義關係的精確表達與語言科技應用。這項資源裡有兩項重要的元素[FF1A?]一是以詞義為據 的詞彙分組 (即所謂的同義詞集(synset))[FF0C?]另一個就是聯繫同義詞集的語意關係 (semantic relations)。以同義詞集為節點[FF0C?]透過語意關係相互聯繫[FF0C?]就形成了表徵詞彙意義及其關係的語意網路[FF0C?]也可視為是以詞義與語意關係為經緯建立的人類語言知識表達基本架構模擬。建構完成的詞匯語意網[FF0C?]一方面可以作為語言學研究的素材[FF0C?]另一方面在各項資訊應用上都可當成是重要元件。

\subsection{15.2 語料庫工具}

如前面提到的[FF0C?]語料庫是最為普遍使用的一種語言資源。不過我們要瞭解到[FF0C?]語料庫本身並不會直接提供給我們資訊。我們需要有假說[FF0C?]有適合的工具。而實證與經驗方法的使用[FF0C?]自然地同步會發展相應的工具集 (toolkits)。我們可以就不同目的把它們分成不同的類型。 從系統實作的角度來說[FF0C?]Kosem and Kosem (\hyperlink{bookmarkid19c6y18}{2011}) 把語料庫工具類型分成幾種對比[FF1A?]單機 vs.線上工具、與特定語料庫有關 vs.獨立於任何語料庫、簡易 vs.進階工具等等。就內容來說[FF0C?]語料庫工具類型包括語料庫的\textbf{建構、預處理、標記}與\textbf{分析}等面向[FF0C?]如下所述:

\begin{itemize}
\item \textbf{建構}

\end{itemize}

所謂的建構包括了語料的搜集 (collection)、清理 (cleaning)、編製索引 (index) 與儲存 (storage) 工作。一開始的語料搜集工作涉及了如何透過程式工具取得語料[FF0C?]以及所搜集到的語料樣本在各式文類 (genre) 與文體 (mode) 的平衡性考量[FF1B?]清理工作則取決於不同研究目的[FF0C?]對於所搜集到之樣本進行訊息保留或清理。編製索引的目的是期許在日後讓語料庫的應用程式可以快速檢索與搜尋[FF0C?]市面上有不少的可能方案如開源的搜尋引擎 \href{https://www.elastic.co}{ElasticSearch}、\href{https://lucene.apache.org}{Apache Lucene}[FF0C?]語料庫語言學社群中也開發了如 \href{http://emdros.org}{Emdros} 和 \href{http://cwb.sourceforge.net}{Corpus WorkBench} 等平台[FF0C?]後者是目前比較受到歡迎與使用的工具平台。

\begin{itemize}
\item \textbf{處理}

\end{itemize}

包括切符 (tokenization)、【中文】斷詞 (或分詞) (word segmentation)、詞類自動標記 (POS tagging)、句法剖析 (parsing)、其他語意或語用等語言學訊息的人工標記 (annotation platform) 或自動標記工具 (tagger) 等。此部分常與計算語言學的研究工作重疊。

\begin{itemize}
\item \textbf{標記}

\end{itemize}

標記任務指的是以人工或半自動機器輔助的方式[FF0C?]將不同層次與面向的語言訊息標在語言單位與序列上。標記好的語料對於語言分析與機器學習有很大的助益。較著名的協作標記工具 (teamware) 有 GATE、MAE、BRAT、WebAnno(Inception)、ANNIS 等等。 除了以上發展較久的標記系統[FF0C?]晚近更有將標記整合到程式處理的架構如 Prodigy + spacy。

\begin{itemize}
\item \textbf{分析}

\end{itemize}

這個部分可以說是語料庫方法的核心成分[FF0C?]包括對語料進行瀏覽、統計、模式抽取等工作[FF0C?]依照不同的研究目的而有區別。廣義的說[FF0C?]我們可以綜整成幾個方向[FF1A?]

\ea%1
    \label{ex:key:1}
    \gll\\
        \\
    \glt
    \z

        . 頻率[FF1A?]所要探究的語言單位[FF08?]字、詞、結構等[FF09?]的類型 (type) 與實例 (token) 的發生次數計量。

\ea%2
    \label{ex:key:2}
    \gll\\
        \\
    \glt
    \z

        . 分佈 (distribution)與聚散 (dispersion)[FF1A?]探究語言單位類型 (type) 與實例 (token) 在語言樣本中的分佈與聚散程度。

\ea%3
    \label{ex:key:3}
    \gll\\
        \\
    \glt
    \z

        . 共現搭配 (coll(oc{\textbar}ig)a{\textbar}ostruc)tion))[FF1A?]探究語言單位或結構之間在類似語境下共同搭配出現的現象。

\ea%4
    \label{ex:key:4}
    \gll\\
        \\
    \glt
    \z

        . 關鍵顯著 (keyness)[FF1A?]探究語言單位在語料庫中的顯著代表性。如關鍵字等。

\ea%5
    \label{ex:key:5}
    \gll\\
        \\
    \glt
    \z

        . 視覺化呈現 (visualization)與圖形特徵計算[FF1A?]探究語言單位之間的全域連結[FF0C?]常結合統計計算與計算語言學模型[FF0C?]如叢聚分析 (cluster analysis)、語意相似度計算 (semantic similarity) 、網路分析 (network analysis)等等。

分析輔助工具上[FF0C?]單機版的語料分析工具是歷史最悠久的工具[FF0C?]例如免費的 \href{http://www.laurenceanthony.net/%20software.html}{Ant*}\href{http://www.laurenceanthony.net/%20software.html}{系列}[FF0C?]到目前為止都是許多語料庫研究者目前仍在使用的分析工具。特 別是 Ant* 系列除了提供常用的文本分析工具[FF0C?]還提供中日文自動斷詞與詞類標記、語步 (move) 標記分析、字元轉換、字彙難易度、語言變異等工具[FF0C?]對於入門的讀者相當實用[FF0C?]值得推薦。此外[FF0C?]英國蘭卡斯特大學語料庫團隊近年也推出了自由軟體 \href{http://corpora.lancs.ac.uk/lancsbox/}{\#LancsBox}[FF0C?]對於搭配詞的網路提供了統計公式調整與視覺化的呈現[FF0C?]對於語料量不大的研究者來說[FF0C?]是一個不錯的分析工具。

\subsubsection{15.2.1 整體式網路服務}

上述的單機版工具雖然小巧方便[FF0C?]但是隨著語料的可得性指數增長[FF0C?]在個人電腦上處理大數據常常會因為計算資源的捉襟見肘而難以順利進行。如果要處理的語料量較大[FF0C?]就需要使用線上的語料分析系統。這些系統提供蒐集與處理好的語料[FF0C?]並提供工具讓人可以線上使用[FF0C?]不需耗費個人電腦的資源。其中比較著名的有當代美語語料庫 \href{https://www.english-corpora.org/coca/}{COCA}、和 \href{https://www.sketchengine.co.uk/}{Word Sketch Engine}。此外[FF0C?]大部分的讀者比較不熟悉的是歐洲的傳統[FF0C?]比方說瑞典哥登堡大學開發的 \href{http://spraakbanken.gu.se/eng}{Språkbanken (the Swedish Language Bank} 甚至整合了如 FrameNet 等詞彙語意資源與標記[FF0C?]使整合性語料庫語言學更向前邁進。而在臺灣正體中文的語料庫研究社群中[FF0C?]向來以使用中研院平衡語料庫 \href{http://asbc.iis.sinica.edu.tw}{ASBC} 為主。不過[FF0C?]隨著語料庫停止收錄更新[FF0C?]比較難以符應語言使用的當代特性[FF0C?]加上語料標記的多元化也漸漸成為整合研究的需要[FF0C?]已有不少規模不大但具有不同特色的漢語語料庫公開提供外界使用[FF0C?]如臺灣師範大學的\href{http://140.122.83.250/cwb_mp3/}{華語為第二語口語語料庫}、政治大學\href{http://140.119.172.200/%20chinese/nuucchi-about.htm}{漢語口語語料庫}、臺灣大學語言所 LOPE 實驗室開發的\href{http://lopen.linguistics.ntu.edu.tw/copens}{開放語料與搜尋系統}\href{http://lopen.linguistics.ntu.edu.tw/copens}{ COPENS} 和動態更新的\href{http://lopen.linguistics.ntu.edu.tw/pttcorp}{批踢踢語料庫}等等。

    這些系統的開發與開放[FF0C?]也促進了語料庫語言學分析工具的創新[FF0C?]讓語言的實證研究更為有趣。比方說 Word Sketch Engine 利用語法規則可以呈現搜尋語詞的語法搭配詞。如下圖以「吃」為例[FF0C?]我們可以觀察到「吃」的主詞、受詞、修飾語等分佈[FF1B?] \href{http://@brezina2018lancsbox}{\#LancsBox} 則提供視覺化工具來呈現搭配詞與搭配詞類 (colligation) 的網路[FF1B?]批踢踢語料庫則致力於建構對話與功能語料庫的架構設計。

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img001.png}
 

圖15-1

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img002.png}
 

圖15-2

\subsubsection{15.2.2 語料庫程式設計}

不過[FF0C?]隨著資料的劇增與資訊科技的快速發展[FF0C?]在許多時候現有的語料庫系統與工具已無法符應研究需求。比方說目前在單機版執行的語料庫工具處理大型資料的能力有限[FF0C?]語料搜尋與處理的趨勢還是以雲端運作為主。而隨著語言分析的層次與廣度[FF0C?]目前語料庫系統提供的功能常常不敷使用[FF0C?]使用者或研究者即便有創新的觀點[FF0C?]也很難期待現有的語料工具開發者能夠迅速地同步更新。此外[FF0C?]目前的數位資料累積與增長的速度已遠遠倍增於人類史上的任何階段[FF0C?]這樣一種巨量資料風潮也改變了人文社會與自然科學研究的面貌在此背景下[FF0C?]直接學習「語料庫程式設計」(corpus programming)[FF0C?]自行開發與解決手邊的研究與實務問題[FF0C?]同時也可回饋社群[FF0C?]造就更廣泛的知識進化與傳播便成了新的學習與研究趨勢。所謂以程式方法研究語料庫[FF0C?]簡單來說就是碰到問題與需要時可以用編寫程式的方法解決。隨著學習工具與網路集體學習的快速發展[FF0C?]目前學習編寫程式的支援環境與資源已相當友善、普及、甚至目不暇給。有興趣的讀者可以參考我們在 2018 年舉辦的\href{https://github.com/lopentu/BestPracticeInCorpusProgramming}{語料庫程式設計入門工作坊}\href{https://github.com/lopentu/BestPracticeInCorpusProgramming}{(}\url{https://github.com/lopentu/BestPracticeInCorpusProgramming})。 以下我們以 R 語言為例[FF0C?]使用 Levshina (\hyperlink{bookmarkid3tbugp1}{2015}) 提供的數據來當成簡單的展演例子。

\textbf{require}(Rling)\\
\textbf{data}(ldt)\\
\textit{\#} \textit{100} \textit{selected} \textit{words} \textit{for} \textit{the} \textit{Lexical} \textit{Decision} \textit{Task}

首先我們載入一個從 English Lexicon Project Balota et al. (\hyperlink{bookmarkid32hioqz}{2007}) 的實驗語料[FF0C?]包含了隨機選出的 100 個英文詞彙[FF0C?]以及它們的詞長、平均反應時間和在語料庫中的使用頻率。之後很快可以以程式 summary(ldt\$Mean\_RT) 得到基本描述統計[FF08?]以平均反應時間為例[FF09?]: 564.18, 713.1125, 784.94, 808.2533, 905.2, 1458.75[FF0C?] 也可以迅速作圖觀察變量之間的關聯與分佈。

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img003.png}
 

圖15-3

或跑統計檢驗shapiro.test(ldt\$Mean\_RT)[FF1B?]

\#\# \\
\#\#  Shapiro-Wilk normality test\\
\#\# \\
\#\# data:  ldt\$Mean\_RT\\
\#\# W = 0.92, p-value = 0.00001

或算出相關係數 (cor(ldt\$Mean\_RT, ldt\$Length) = 0.6147) 得知字長與反應時間的正相關[FF1B?]或跑散佈圖與跑迴歸分析等等。

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img004.png}
 

圖15-4

\subsection{15.3 語言研究的實證方法}

當然[FF0C?]會寫程式不等於能夠做研究。接下來我們就具體一點的來談如何運用實證方法 (empirical method) 來探究語言。 不過我得預設讀者具備基礎的統計知識[FF0C?]這也是實證方法的基本先備知識之一。 因為我們採取是經驗性的觀點來分析語言[FF0C?]從抽象的理論到具體的觀察之間是有逐層的處理步驟可以參照。(Manheim et al. \hyperlink{bookmarkidnmf14n}{2008}) 用以下的圖示說明了在經驗實證方法中概念 (concept)、變項 (variable) 與指標量度 (indicator/values) 之間的關係。

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img005.png}
 

圖15-5

左右欄是一個理論構想與實證方法的對應。首先我們對於關心的語言現象有理論預想[FF0C?]對應到右邊就是指某概念與某概念之間有某種關連。理論會有假說 (hypothesis)[FF0C?]但是在實證研究中必須經過\textbf{「操作化」(operationalized)} 的轉換過程。所謂可操作化是一個選擇可觀察到的具體現象來表徵抽象概念的過程。為了做到這件事[FF0C?]我們必須找到量度工具用來量化地表達我們假說中的概念。再者我們要了解[FF0C?]經驗研究中所謂的「可觀察到的」[FF0C?]指的是要分析的現象特徵是可以藉由量度工具來賦值的。這樣說有點抽象[FF0C?]舉例來說[FF0C?]我們有興趣探究到底文法系統是內在的模組化系統[FF0C?]還是外在學習突現出來動態系統的這麼大的主題。(Goodman \hyperlink{bookmarkidvx1227}{1997}) 提出了可以觀察「\textit{詞彙量」} (vocabulary size) 和 16-30 個月大的小孩的\textit{「文法發展」} (grammatical development) 這兩個變項之間的關係[FF0C?]並假設了它們之間存在著正相關。他們將變項作的「操作化」就是\textit{詞彙量} 以「受試小孩子所產出的詞彙數量」來量度[FF0C?]而文法發展則是以「所學到的構式數量」(作者先預先定義了 37 種構式)。假說的右邊對應就是將假說操作化為變量之間的關聯。接著我們會有所謂作業假說 (working hypothesis)[FF0C?]這與以下會提到的「探索性分析」密切關聯。可以把它當成是一種臨時接受的假說[FF0C?]希望透過探索分析得到驗證或拒絕[FF0C?]作為進一步研究的基礎。最後就是實際的觀察值的蒐集代入。到這裡我們可以看出[FF0C?]經驗方法的好處之一在於如果實驗資料是公開或是可模擬的[FF0C?]我們就可以重製 (reproduce) 之前的實驗[FF0C?]並在其基礎下往前繼續深入探究。

\subsubsection{15.3.1 程序}

在實際的資料分析流程上[FF0C?]有一個一步一步來的慣例規約 (protocol)。下圖大概表示了這樣的流程。但要注意每個模組裡都有更細緻的子模組[FF0C?]模組之間的運作也並不是單向式的[FF0C?]而是「來來回回」(back and forth) 的互動。每個步驟都有相應需要注意的地方。

%%[Warning: Draw object ignored]

圖15-6: 語料實證分析流程

假設我們對於中文單音節詞 (就是由單一漢字所構成的詞所組成的詞) 的心理處理歷程有興趣[FF0C?]並假設不同的\textbf{使用頻率}與\textbf{反應時間}會有造成不同的效應。那麼採取經驗方法的話會涉及哪些步驟呢[FF1F?]以下我們用 Sun et al. (\hyperlink{bookmarkid1mrcu09}{2018}) 這篇論文所提供的現代漢語心理詞庫資料[FF0C?]來重製部分實驗(見以下引自原文的表格)與說明實證經驗方法的程序與好處。

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img006.png}
 

\parencite{SunEtAl2018} 這篇文章介紹了一個開放下載的中文心理詞庫 (Chinese Lexicon Database, CLD.  \url{http://www.chineselexicaldatabase.com})。這個詞庫提供了許多現代漢語詞彙的各種心理實驗數據[FF0C?]方便研究者進行不同的語言實證研究。不過這個資源是基於簡體中文[FF0C?]假定我們想先重製詞彙判斷作業反應時間 (lexical decision latencies) 與從語料庫抽取出來的頻率之間的關聯實驗[FF0C?]並看看在正體中文是否會得到類似結果[FF0C?]或觀察不同時間取得的頻率[FF0C?]是否結果相似。

\textbf{資料取得}

我們首先從 \href{http://www.chineselexicaldatabase.com/}{CLD} 取出資料[FF0C?]這個 CLD 詞庫 (v.2.1) 中包含了48,644 個漢語詞彙[FF0C?]及其在 269 個變項的數值。 利用我們開發的 R 套件 lexicoR (https://lopentu.github.io/lexicoR/articles/databases.html[FF09?][FF0C?]很方便的即可取得所有的資料。以變數項目來說[FF0C?]就有字形筆畫數、使用頻率、字長、音節、熟悉度、聲調、鄰近密度量度、詞彙判斷作業反應時間 (RT)、字詞命名反應時間、資訊熵值量度等等。 

\textbf{前處理}

因為我們要重製部分實驗[FF0C?]因此不是所有的變量都用得到。 在此我們只取出單音節詞、與作為回應變量 (response variable) 的反應時間( RT,毫秒單位) 、作為解釋變量 (explanatory variable)的其他幾個變量[FF08?]如轉成正體字的筆畫數、從不同時期批踢踢語料庫計算出來的詞頻等等[FF09?]。此外[FF0C?]我們有時候也需要改變量名稱增加可讀性。經過前處理之後的資料大概長這樣[FF1A?]

\tablefirsthead{}

\tabletail{}
\tablelasttail{}
\begin{tabularx}{\textwidth}{XXXXXXXXXXX}
\lsptoprule
Character & \multicolumn{2}{X}{RT} & \multicolumn{2}{X}{cld.Frequency} & cld.C1Frequency & \multicolumn{2}{X}{cld.C1Strokes} & \multicolumn{2}{X}{pttFreq.2004\_2009} & \\
\hhline{----------~}
啊 & \multicolumn{2}{X}{583.6} & \multicolumn{2}{X}{4215.2187} & 3242.1679 & \multicolumn{2}{X}{11} & \multicolumn{2}{X}{0.0021} & \\
{}哎 & \multicolumn{2}{X}{568.3} & \multicolumn{2}{X}{163.9066} & 167.763 & \multicolumn{2}{X}{9} & \multicolumn{2}{X}{0} & \\
{}哀 & \multicolumn{2}{X}{578.6} & \multicolumn{2}{X}{2.9281} & 42.4741 & \multicolumn{2}{X}{9} & \multicolumn{2}{X}{0} & \\
{}唉 & \multicolumn{2}{X}{688.1} & \multicolumn{2}{X}{141.4085} & 109.2691 & \multicolumn{2}{X}{10} & \multicolumn{2}{X}{0.0002} & \\
{}埃 & \multicolumn{2}{X}{720.2} & \multicolumn{2}{X}{2.4018} & 39.8963 & \multicolumn{2}{X}{10} & \multicolumn{2}{X}{0} & \\
{}挨 & \multicolumn{2}{X}{681.6} & \multicolumn{2}{X}{20.3558} & 24.6914 & \multicolumn{2}{X}{10} & \multicolumn{2}{X}{0} & \\
{}挨 & \multicolumn{2}{X}{681.6} & \multicolumn{2}{X}{20.3558} & 24.6914 & \multicolumn{2}{X}{10} & \multicolumn{2}{X}{0} & \\
{}癌 & \multicolumn{2}{X}{598} & \multicolumn{2}{X}{1.4678} & 28.4938 & \multicolumn{2}{X}{17} & \multicolumn{2}{X}{0} & \\
{}矮 & \multicolumn{2}{X}{601.1} & \multicolumn{2}{X}{22.7279} & 21.4272 & \multicolumn{2}{X}{13} & \multicolumn{2}{X}{0} & \\
{}艾 & \multicolumn{2}{X}{593.7} & \multicolumn{2}{X}{7.487} & 67.9358 & \multicolumn{2}{X}{5} & \multicolumn{2}{X}{0} & \\
{}爱 & \multicolumn{2}{X}{497.1} & \multicolumn{2}{X}{2042.6093} & 2633.6889 & \multicolumn{2}{X}{10} & \multicolumn{2}{X}{0.0008} & \\
{}碍 & \multicolumn{2}{X}{675.3} & \multicolumn{2}{X}{3.3136} & 38.3012 & \multicolumn{2}{X}{13} & \multicolumn{2}{X}{0} & \\
{}安 & \multicolumn{2}{X}{512.1} & \multicolumn{2}{X}{34.2698} & 1186.3111 & \multicolumn{2}{X}{6} & \multicolumn{2}{X}{0} & \\
{}鞍 & \multicolumn{2}{X}{655.9} & \multicolumn{2}{X}{0.1927} & 2.7556 & \multicolumn{2}{X}{15} & \multicolumn{2}{X}{0} & \\
{}谙 & \multicolumn{2}{X}{827.1} & \multicolumn{2}{X}{0.5263} & 0.7309 & \multicolumn{2}{X}{11} & \multicolumn{2}{X}{0} & \\
\multicolumn{2}{X}{} & \multicolumn{2}{X}{} & \multicolumn{3}{X}{} & \multicolumn{2}{X}{} & \multicolumn{2}{X}{}\\
\lspbottomrule
\end{tabularx}
\textbf{探索分析與可視化}

接著[FF0C?]在進入資料分析之前有幾件事需要注意[FF1A?]處理缺失值 (missing value) 與異常值 (outliers)、檢查共變量之間的共線性 (collinearity)、樣本誤差等。這些都是所謂「探索資料分析」(exploratory data analysis) 的步驟中需要注意的部分[FF0C?]通常可以藉由視覺化技術更好的呈現與挖掘。 比方說[FF0C?]我們需要先看看 CLD 中的在詞彙反應作業任務中[FF0C?]頻率、平均反應時間與筆畫數之間共線性的檢查[FF0C?]可以用 multi-panel 散佈圖和皮爾森關聯係數。

\textbf{統計建模}

我們大概知道了變量的基本量化特徵[FF0C?]變項之間的關聯[FF0C?]如果我們要進一步了解資料底層的模式與互動機制[FF0C?]我們就需要使用統計模型。所謂統計「建模」(modeling) 其實就是把我們的對於現象的觀察心得轉譯成數學式子。以反應時間與使用頻率兩個變量來說[FF0C?]我們可以建立線性迴歸模型[FF0C?]得到

\#\# \\
\#\# Call:\\
\#\# lm(formula = Mean\_RT {\textasciitilde} LogFreq, data = LDT1)\\
\#\# \\
\#\# Residuals:\\
\#\#    Min     1Q Median     3Q    Max \\
\#\#   {}-145    {}-38     {}-7     31    291 \\
\#\# \\
\#\# Coefficients:\\
\#\#             Estimate Std. Error t value\\
\#\# (Intercept)   626.37       1.81     345\\
\#\# LogFreq       {}-15.73       0.56     {}-28\\
\#\#                        Pr(>{\textbar}t{\textbar})\\
\#\# (Intercept) <0.0000000000000002\\
\#\# LogFreq     <0.0000000000000002\\
\#\# \\
\#\# Residual standard error: 56 on 2414 degrees of freedom\\
\#\# Multiple R-squared:  0.24,   Adjusted R-squared:  0.24 \\
\#\# F-statistic: 7.8e+02 on 1 and 2414 DF,  p-value: <0.0000000000000002

因為語言現象總是涉及了許多變項。我們如果想要看變項之間的關係[FF0C?]與其對於現象/模型的影響[FF0C?]通常引入\textbf{複迴歸分析} (multiple regression)[FF0C?]這裏就不再細談。

\subsubsection{15.3.2 方法論上的考量}

在第 1 節中我們提到的基於使用的語言觀點中[FF0C?]頻率是個極為關鍵的概念。 Gries and Ellis (\hyperlink{bookmarkid2u6wntf}{2015}) 特別指出語言使用的頻率計算上[FF0C?]有許多值得注意的地方[FF1A?]

\begin{itemize}
\item 操作化不免會簡化問題的本質。

\item 好語料決定大部分模型的結果。

\item 分析的透明性與重製實驗的設計。

\end{itemize}

儘管採取實證方法[FF0C?]許多研究僅僅提供統計檢定與最後實驗成果[FF0C?]不提供實驗數據 而無法重製實驗[FF0C?]這也是造成許多研究要累積往前可能的障礙之一。此外[FF0C?] 實證與量化方法可以說是取得很大的成就。但是我們同時需要注意單一思維與研究取徑總是有其相當的限制[FF0C?]比方說[FF1A?]

\begin{itemize}
\item 統計上的關聯 (correlation)並 不保證因果 (causality)。

\item 避免「擇優挑選」(cherry-picking) 的建模過程。

\item 數據的取得與種種限制[FF0C?]使得語料庫與認知的對應 (from-corpus-to-cognition) 關係建立要相當謹慎。

\item 中文語料的斷詞問題[FF0C?]在巨量語料庫時代因為失去人工檢查的可能[FF0C?]隨著語料的擴增[FF0C?]雖然微量的斷詞錯誤累積後仍會導致分析的失準。

\end{itemize}
\subsection{15.4 應用}

有了語料庫[FF0C?]我們觀察語言多了更具備經驗、實證性的角度。此外[FF0C?]也容易與資料科學、自然語言處理[FF08?]計算語言學[FF09?]等資料密集的學門有進一步的連結與互動。以下我們將以語言的變遷與計算語言方法來說明。

我們之前都是利用語料庫來研究語言的「橫的軸向」[FF0C?]我們也可以用不同時期的語料來做語言的「縱的軸向」探究[FF0C?]以實證語料為本去看語言在不同層次的變遷、演化等問題。隨著巨量歷時語料的增加[FF0C?]許多學者例如 Michel et al. (\hyperlink{bookmarkid37m2jsg}{2011}) 開始嘗試用 Google 從 1800 年開始數位化的書籍資料進行語詞的量化觀察[FF0C?]並探究語詞的歷時使用分佈與「文法演化」的問題。這樣的資料導向分析法[FF0C?]更便利了跨學門的整合觀察[FF0C?]我們有機會從語言、文化與社會的角度來了解不同的現象[FF08?]所謂的「文化資訊學」(culturomics) 也因此誕生[FF09?]。

我們可以「老婆、太太、愛人」為例[FF0C?]搜尋並取得 Google Book ngram 跨兩百多年的書籍 N 連詞 (n-gram) 使用頻率資料[FF0C?]如下圖顯示[FF0C?]可以看到太太的稱謂在 1940-50 年左右達到高峰[FF0C?]對照國民政府時期的官太太文化[FF0C?]也許可以得到相應的理解。  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img007.png}
 

圖15-7

不過正如 Brezina (\hyperlink{bookmarkid41mghml}{2018}) 的提醒[FF0C?]如果沒有進入脈絡去觀察(如我們先前提到的 concordance 環境)[FF0C?]很有可能會有嚴重的誤讀。

晚近在計算語言學的分佈式與分散式語意表徵[FF08?]如詞嵌入 word embeddings[FF0C?]請參見第 16 章[FF09?]的進展[FF0C?]可以將共現脈絡訊息某個程度地抽象化投射到低維度高稠密的向量空間[FF0C?]使得語言的使用可以用向量的表徵與運算來運作。 這種基於語境數據的向量表徵[FF0C?]對於語言研究也帶來新一波的視野。我們 (Chen and Hsieh, 2019) 利用了中文文史哲歷史文獻 CTEX[FF0C?]與其他歷時語料建立了漢語跨千年的歷時語料庫[FF0C?]方便對於語詞的概念變遷做實證的分析與觀察。下圖的例子[FF0C?]是利用這樣的語料庫[FF0C?]我們可以利用搭配詞看到「家」的規則多義 (regular polysemy) 隨著時代在「人的關係組合」、「居住處」、「成員」之間的語意變遷。例如從圖 15-9 的家\_9的變化來看[FF0C?]這個詞義比較像是「每一<家>的拳法皆不相同[FF0C?]走步也不相同[FF0C?]好像基本的馬步是一定有的。」中的意思[FF0C?]而隨著時代演變[FF0C?]這樣的用法日漸罕見。  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img008.png}
 

圖15-8

  
%%please move the includegraphics inside the {figure} environment
%%\includegraphics[width=\textwidth]{figures/test15-img009.png}
 

圖15-9

\subsection{15.5 總結與摘要}

本章介紹了我們要探究語言現象時[FF0C?]可以採取的實證研究方法。

語料庫就像是語言使用的收集[FF0C?]基於語料庫來從事語言研究[FF0C?]不論在語言結構本身[FF08?]語音、構詞、句法、語意等[FF09?][FF0C?]或是語言的形塑因素[FF08?]認知、文化社會、歷史[FF09?]等方面都有了長足的進展。此外[FF0C?]語料庫對於資料科學 (data science)、文本採礦 (text mining) 與自然語言處理 (natural language processing) 等語言相關的科技發展有著密切的關係。

讀者若對於語料庫程式設計有興趣[FF0C?]以下是可以參考的書籍。

\begin{itemize}
\item (Levshina \hyperlink{bookmarkid3tbugp1}{2015}) 的 \textbf{How} \textbf{to} \textbf{do} \textbf{linguistics} \textbf{with} \textbf{R} 是不錯的入門書。

\item (Brezina \hyperlink{bookmarkid41mghml}{2018}) 和 (Gries \hyperlink{bookmarkid3fwokq0}{2009}, \hyperlink{bookmarkid1v1yuxt}{2010}, \hyperlink{bookmarkid4f1mdlm}{2016}) 則是語料庫統計的一般性介紹。可以和 \#LancsBox 的線上課程一起搭配學習[FF08?] \url{http://corpora.lancs.ac.uk/lancsbox/materials.php}[FF09?]。

\item (Winter \hyperlink{bookmarkid46r0co2}{2019}) \textbf{Statistics} \textbf{for} \textbf{Linguists:} \textbf{An} \textbf{Introduction} \textbf{Using} \textbf{R} 則是語料庫統計學的入門好書。

\end{itemize}
% \subsection{15.6 參考文獻}

% \hypertarget{bookmarkid32hioqz}{}Balota, David A, Melvin J Yap, Keith A Hutchison, Michael J Cortese, Brett Kessler,   Bjorn Loftis, James H Neely, Douglas L Nelson, Greg B Simpson, and Rebecca Treiman. 2007. “The English Lexicon Project.” \textit{Behavior} \textit{Research} \textit{Methods} 39 \REF{ex:key:3}. Springer: 445–59.

% \hypertarget{bookmarkid41mghml}{}Brezina, Vaclav. 2018. \textit{Statistics} \textit{in} \textit{Corpus} \textit{Linguistics:} \textit{A} \textit{Practical} \textit{Guide}. Cambridge University Press.

% \hypertarget{bookmarkid2grqrue}{}Diessel, Holger. 2017. “Usage-Based Linguistics.” In \textit{Oxford} \textit{Research} \textit{Encyclopedia} \textit{of} \textit{Linguistics}.

% \hypertarget{bookmarkidvx1227}{}Goodman, Elizabeth Bates Judith C. 1997. “On the Inseparability of Grammar and the Lexicon: Evidence from Acquisition, Aphasia and Real-Time Processing.” \textit{Language} \textit{and} \textit{Cognitive} \textit{Processes} 12 (5-6). Taylor \& Francis: 507–84.

% \hypertarget{bookmarkid3fwokq0}{}Gries, Stefan Th. 2009. \textit{Statistics} \textit{for} \textit{Linguistics} \textit{with} \textit{R:} \textit{A} \textit{Practical} \textit{Introduction}. Vol. 208. Walter de Gruyter.

% \hypertarget{bookmarkid1v1yuxt}{}———. 2010. “Useful Statistics for Corpus Linguistics.” \textit{A} \textit{Mosaic} \textit{of} \textit{Corpus} \textit{Linguistics:} \textit{Selected} \textit{Approaches} 66: 269–91.

% \hypertarget{bookmarkid4f1mdlm}{}———. 2016. \textit{Quantitative} \textit{Corpus} \textit{Linguistics} \textit{with} \textit{R:} \textit{A} \textit{Practical} \textit{Introduction}. Taylor \& Francis.

% \hypertarget{bookmarkid2u6wntf}{}Gries, Stefan Th, and Nick C Ellis. 2015. “Statistical Measures for Usage-Based Linguistics.” \textit{Language} \textit{Learning} 65 (S1). Wiley Online Library: 228–55.

% Gries, Stefan Th. 2019. “\textit{Ten} \textit{Lectures} \textit{on} \textit{Corpus} \textit{Linguistics} \textit{with} \textit{R:} \textit{Applications} \textit{for} \textit{Usage-based} \textit{and} \textit{Psychological} \textit{Research”}. Brill Publisher.

% \hypertarget{bookmarkid19c6y18}{}Kosem, Iztok, and Karmen Kosem. 2011. “Electronic Lexicography in the 21st Century: New Applications for New Users.” \textit{Proceedings} \textit{of} \textit{e\citealt{Lex2011}}. Citeseer.

% \hypertarget{bookmarkid3tbugp1}{}Levshina, Natalia. 2015. \textit{How} \textit{to} \textit{Do} \textit{Linguistics} \textit{with} \textit{R:} \textit{Data} \textit{Exploration} \textit{and} \textit{Statistical} \textit{Analysis}. John Benjamins Publishing Company.

% \hypertarget{bookmarkid28h4qwu}{}Luodonpää-Manni, Milla, Esa Penttilä, and Johanna Viimaranta. 2017. \textit{Empirical} \textit{Approaches} \textit{to} \textit{Cognitive} \textit{Linguistics:} \textit{Analyzing} \textit{Real-Life} \textit{Data}. Cambridge Scholars Publishing.

% \hypertarget{bookmarkidnmf14n}{}Manheim, Jarol B, Richard C Rich, Lars Willnat, and Craig Leonard Brians. 2008. \textit{Empirical} \textit{Political} \textit{Analysis:} \textit{Quantitative} \textit{and} \textit{Qualitative} \textit{Research} \textit{Methods}. Longman Pub Group.

% \hypertarget{bookmarkid37m2jsg}{}Michel, Jean-Baptiste, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K Gray, Joseph P Pickett, Dale Hoiberg, et al. 2011. “Quantitative Analysis of Culture Using Millions of Digitized Books.” \textit{Science} 331 \REF{ex:key:6014}. American Association for the Advancement of Science: 176–82.

% \hypertarget{bookmarkid1mrcu09}{}Sun, Ching Chu, Peter Hendrix, Jianqiang Ma, and Rolf Harald Baayen. 2018. “Chinese Lexical Database (Cld).” \textit{Behavior} \textit{Research} \textit{Methods} 50 \REF{ex:key:6}. Springer: 2606–29.

% \hypertarget{bookmarkid46r0co2}{}Winter, Bodo. 2019. \textit{Statistics} \textit{for} \textit{Linguists:} \textit{An} \textit{Introduction} \textit{Using} \textit{R}. Routledge.

% \hypertarget{bookmarkid2lwamvv}{}Zipf, George Kingsley. 1949. “Human Behavior and the Principle of Least Effort.” addison-wesley press.


% \begin{verbatim}%%move bib entries to  localbibliography.bib
% \end{verbatim} 